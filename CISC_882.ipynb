{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 04:16:12.009604: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 04:16:12.025942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733112972.044788   60329 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733112972.050514   60329 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 04:16:12.070430: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "import patient_data\n",
    "import cnn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the folder path for the cancer and the non-cancer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = json.loads(open(\"./paths.json\").read())\n",
    "\n",
    "personal_path = all_paths['personal_path']\n",
    "non_cancerous_path = personal_path + all_paths['non_cancerous_path']\n",
    "cancerous_path = personal_path + all_paths['cancerous_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the DICOM files and preprocess/label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints was not processed correctly\n"
     ]
    }
   ],
   "source": [
    "# Using the patient_data data structure, load in all the patient data and save it in a dictionary with the folder name as the key\n",
    "def load_all_patients(path, add_label = False):\n",
    "    patients = {}\n",
    "    folder = os.listdir(path)\n",
    "    for name in folder:\n",
    "        patients[name] = patient_data.Patient(os.path.join(path, name))\n",
    "        if add_label:\n",
    "            if patients[name].segpath == None:\n",
    "                print(name, \"was not processed correctly\")\n",
    "                patients.pop(name)\n",
    "            else:\n",
    "                patients[name].label_imgs()\n",
    "    return patients\n",
    "\n",
    "# nc_patients = load_all_patients(non_cancerous_path)\n",
    "c_patients = load_all_patients(cancerous_path, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not sure if we need this\n",
    "# # create a list for the merged data\n",
    "# x = []\n",
    "# y = []\n",
    "\n",
    "# create a list for only the cancerous dataset data\n",
    "x_c = []\n",
    "y_c = []\n",
    "# # create a list for only the non-cancerous dataset data\n",
    "# x_nc = []\n",
    "# y_nc = []\n",
    "\n",
    "for patient in c_patients.values():\n",
    "    for i, img in enumerate(patient.ct.data.values()):\n",
    "        x_c.append(img)\n",
    "        y_c.append(patient.labels[i])\n",
    "        # # not sure if we need this\n",
    "        # x.append(img)\n",
    "        # y.append(patient.labels[i])\n",
    "\n",
    "x_c, y_c = shuffle(x_c, y_c)\n",
    "c_patients = None\n",
    "\n",
    "# for patient in nc_patients.values():\n",
    "#     for i, img in enumerate(patient.ct.images):\n",
    "#         x_nc.append(img)\n",
    "#         y_nc.append(patient.labels[i])\n",
    "#         # # not sure if we need this\n",
    "#         # x.append(img)\n",
    "#         # y.append(patient.labels[i])\n",
    "\n",
    "# # not sure if we need this\n",
    "# # Shuffle the merged data\n",
    "# combined = list(zip(x, y))\n",
    "# np.random.shuffle(combined)\n",
    "# x2, y2 = zip(*combined)\n",
    "\n",
    "# def generate_train_test():\n",
    "#     # to ensure equal distribution of non-cancer to cancer data, split the data before merging it\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x_c, y_c, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # x_train_add, x_test_add, y_train_add, y_test_add = train_test_split(x_nc, y_nc, test_size=0.2, random_state=42)\n",
    "#     # x_train.extend(x_train_add) \n",
    "#     # x_test.extend(x_test_add) \n",
    "#     # y_train.extend(y_train_add) \n",
    "#     # y_test.extend(y_test_add) \n",
    "\n",
    "#     # Convert lists to arrays\n",
    "#     x_train = np.array(x_train)/255\n",
    "#     x_test = np.array(x_test)/255\n",
    "#     y_train = np.array(y_train)\n",
    "#     y_test = np.array(y_test)\n",
    "\n",
    "#     return x_train, x_test, y_train, y_test, x_train[0]\n",
    "\n",
    "# x_train, x_test, y_train, y_test, test = generate_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Num GPUs Available: ', len(physical_devices))\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training fold 1/3\n",
      "point a passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1733113072.105727   60329 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43598 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point b passed\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733113105.035784   60733 service.cc:148] XLA service 0x7f58c80046a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733113105.035843   60733 service.cc:156]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2024-12-02 04:18:25.115212: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733113105.254119   60733 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-02 04:18:25.347016: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   7/2037\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 22ms/step - accuracy: 0.5516 - loss: 0.8358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733113107.719618   60733 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 33ms/step - accuracy: 0.8540 - loss: 0.3578 - val_accuracy: 0.8863 - val_loss: 0.2377\n",
      "Epoch 2/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9017 - loss: 0.2204 - val_accuracy: 0.9284 - val_loss: 0.1740\n",
      "Epoch 3/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 24ms/step - accuracy: 0.9327 - loss: 0.1567 - val_accuracy: 0.9437 - val_loss: 0.1399\n",
      "Epoch 4/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9560 - loss: 0.1108 - val_accuracy: 0.9485 - val_loss: 0.1256\n",
      "Epoch 5/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9649 - loss: 0.0922 - val_accuracy: 0.9620 - val_loss: 0.1067\n",
      "Epoch 6/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9777 - loss: 0.0656 - val_accuracy: 0.9641 - val_loss: 0.0934\n",
      "Epoch 7/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9856 - loss: 0.0450 - val_accuracy: 0.9671 - val_loss: 0.0876\n",
      "Epoch 8/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0384 - val_accuracy: 0.9535 - val_loss: 0.1313\n",
      "Epoch 9/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9915 - loss: 0.0279 - val_accuracy: 0.9710 - val_loss: 0.0795\n",
      "Epoch 10/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9928 - loss: 0.0243 - val_accuracy: 0.9716 - val_loss: 0.0838\n",
      "Epoch 11/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9947 - loss: 0.0193 - val_accuracy: 0.9730 - val_loss: 0.0847\n",
      "Epoch 12/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9941 - loss: 0.0210 - val_accuracy: 0.9746 - val_loss: 0.0861\n",
      "Epoch 13/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 0.9762 - val_loss: 0.0760\n",
      "Epoch 14/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0108 - val_accuracy: 0.9665 - val_loss: 0.0975\n",
      "Epoch 15/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9970 - loss: 0.0118 - val_accuracy: 0.9711 - val_loss: 0.0967\n",
      "Epoch 16/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0086 - val_accuracy: 0.9766 - val_loss: 0.0774\n",
      "Epoch 17/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 0.9741 - val_loss: 0.0958\n",
      "Epoch 18/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 0.9756 - val_loss: 0.0852\n",
      "Epoch 19/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9754 - val_loss: 0.0944\n",
      "Epoch 20/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.9751 - val_loss: 0.0953\n",
      "Model architecture built\n",
      "point c passed\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      8664\n",
      "           1       0.92      0.91      0.92      1517\n",
      "\n",
      "    accuracy                           0.98     10181\n",
      "   macro avg       0.95      0.95      0.95     10181\n",
      "weighted avg       0.98      0.98      0.98     10181\n",
      "\n",
      "\n",
      "Training fold 2/3\n",
      "point a passed\n",
      "point b passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 31ms/step - accuracy: 0.8489 - loss: 0.3499 - val_accuracy: 0.8631 - val_loss: 0.2947\n",
      "Epoch 2/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9105 - loss: 0.2045 - val_accuracy: 0.9113 - val_loss: 0.1976\n",
      "Epoch 3/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9403 - loss: 0.1481 - val_accuracy: 0.9356 - val_loss: 0.1447\n",
      "Epoch 4/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9604 - loss: 0.1085 - val_accuracy: 0.9488 - val_loss: 0.1209\n",
      "Epoch 5/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9711 - loss: 0.0787 - val_accuracy: 0.9554 - val_loss: 0.1054\n",
      "Epoch 6/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9818 - loss: 0.0558 - val_accuracy: 0.9498 - val_loss: 0.1275\n",
      "Epoch 7/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 25ms/step - accuracy: 0.9860 - loss: 0.0454 - val_accuracy: 0.9530 - val_loss: 0.1141\n",
      "Epoch 8/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9873 - loss: 0.0399 - val_accuracy: 0.9675 - val_loss: 0.0851\n",
      "Epoch 9/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9905 - loss: 0.0309 - val_accuracy: 0.9694 - val_loss: 0.0830\n",
      "Epoch 10/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9928 - loss: 0.0238 - val_accuracy: 0.9698 - val_loss: 0.0817\n",
      "Epoch 11/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9944 - loss: 0.0197 - val_accuracy: 0.9699 - val_loss: 0.0824\n",
      "Epoch 12/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.9703 - val_loss: 0.0877\n",
      "Epoch 13/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9961 - loss: 0.0145 - val_accuracy: 0.9667 - val_loss: 0.1024\n",
      "Epoch 14/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0117 - val_accuracy: 0.9721 - val_loss: 0.0856\n",
      "Epoch 15/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9979 - loss: 0.0098 - val_accuracy: 0.9719 - val_loss: 0.0879\n",
      "Epoch 16/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0090 - val_accuracy: 0.9729 - val_loss: 0.0876\n",
      "Epoch 17/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0086 - val_accuracy: 0.9694 - val_loss: 0.1103\n",
      "Epoch 18/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0085 - val_accuracy: 0.9734 - val_loss: 0.0908\n",
      "Epoch 19/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9646 - val_loss: 0.1226\n",
      "Epoch 20/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0069 - val_accuracy: 0.9696 - val_loss: 0.1131\n",
      "Model architecture built\n",
      "point c passed\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      8664\n",
      "           1       0.88      0.93      0.90      1517\n",
      "\n",
      "    accuracy                           0.97     10181\n",
      "   macro avg       0.93      0.95      0.94     10181\n",
      "weighted avg       0.97      0.97      0.97     10181\n",
      "\n",
      "\n",
      "Training fold 3/3\n",
      "point a passed\n",
      "point b passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 33ms/step - accuracy: 0.8562 - loss: 0.3482 - val_accuracy: 0.8954 - val_loss: 0.2310\n",
      "Epoch 2/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9107 - loss: 0.2101 - val_accuracy: 0.9302 - val_loss: 0.1685\n",
      "Epoch 3/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9400 - loss: 0.1431 - val_accuracy: 0.9402 - val_loss: 0.1425\n",
      "Epoch 4/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9582 - loss: 0.1088 - val_accuracy: 0.9256 - val_loss: 0.1620\n",
      "Epoch 5/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9687 - loss: 0.0832 - val_accuracy: 0.9595 - val_loss: 0.1056\n",
      "Epoch 6/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9789 - loss: 0.0615 - val_accuracy: 0.9644 - val_loss: 0.0975\n",
      "Epoch 7/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9854 - loss: 0.0450 - val_accuracy: 0.9694 - val_loss: 0.0914\n",
      "Epoch 8/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9900 - loss: 0.0363 - val_accuracy: 0.9701 - val_loss: 0.0869\n",
      "Epoch 9/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9917 - loss: 0.0301 - val_accuracy: 0.9692 - val_loss: 0.0975\n",
      "Epoch 10/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9935 - loss: 0.0230 - val_accuracy: 0.9592 - val_loss: 0.1151\n",
      "Epoch 11/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9932 - loss: 0.0227 - val_accuracy: 0.9733 - val_loss: 0.0835\n",
      "Epoch 12/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9943 - loss: 0.0182 - val_accuracy: 0.9746 - val_loss: 0.0793\n",
      "Epoch 13/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9753 - val_loss: 0.0852\n",
      "Epoch 14/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0137 - val_accuracy: 0.9742 - val_loss: 0.0883\n",
      "Epoch 15/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 24ms/step - accuracy: 0.9971 - loss: 0.0118 - val_accuracy: 0.9671 - val_loss: 0.1070\n",
      "Epoch 16/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0097 - val_accuracy: 0.9728 - val_loss: 0.0929\n",
      "Epoch 17/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0096 - val_accuracy: 0.9735 - val_loss: 0.0952\n",
      "Epoch 18/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0089 - val_accuracy: 0.9754 - val_loss: 0.0926\n",
      "Epoch 19/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0047 - val_accuracy: 0.9759 - val_loss: 0.0947\n",
      "Epoch 20/20\n",
      "\u001b[1m2037/2037\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0057 - val_accuracy: 0.9655 - val_loss: 0.1325\n",
      "Model architecture built\n",
      "point c passed\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      8663\n",
      "           1       0.96      0.80      0.87      1518\n",
      "\n",
      "    accuracy                           0.97     10181\n",
      "   macro avg       0.96      0.90      0.93     10181\n",
      "weighted avg       0.97      0.97      0.96     10181\n",
      "\n",
      "\n",
      "Average Accuracy Across 3 Folds: 0.9701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras import backend as K\n",
    "# Define K-Fold Cross-Validation\n",
    "n_splits = 3\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "x_data = np.array(x_c)/255  # Normalize the images\n",
    "y_data = np.array(y_c)\n",
    "# Model training and evaluation loop\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(x_c, y_c)):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    x_train, x_val = x_data[train_idx], x_data[val_idx]\n",
    "    y_train, y_val = y_data[train_idx], y_data[val_idx]\n",
    "    print('point a passed')\n",
    "\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print('point b passed')\n",
    "\n",
    "\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=10,\n",
    "        epochs=20,\n",
    "        callbacks=[MyCustomCallback()],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model architecture built\")\n",
    "    print('point c passed')\n",
    "    # Evaluate the model\n",
    "    predictions = (model.predict(x_val) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_val, predictions, output_dict=True)\n",
    "    print(classification_report(y_val, predictions))\n",
    "    \n",
    "    # Save fold results\n",
    "    fold_results.append(report)\n",
    "    K.clear_session()\n",
    "\n",
    "\n",
    "# Aggregate results\n",
    "avg_accuracy = np.mean([fold['accuracy'] for fold in fold_results])\n",
    "print(f\"\\nAverage Accuracy Across {n_splits} Folds: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 05:56:22.154797: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-02 05:56:22.781406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733118983.010492   96129 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733118983.073945   96129 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 05:56:23.668822: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     saliency \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_max(tf\u001b[38;5;241m.\u001b[39mabs(grads), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saliency[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 29\u001b[0m test_image_array \u001b[38;5;241m=\u001b[39m \u001b[43mx_c\u001b[49m  \u001b[38;5;66;03m# Replace 'processed_image' with your actual preprocessed variable\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(test_image_array, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m     test_image_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(test_image_array)  \u001b[38;5;66;03m# Convert list of tensors to a single 4D tensor\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_c' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "def getgradcam_heatmap_fixed(model, img_array, last_conv_layer):\n",
    "    grad_model = Model(inputs=model.input, outputs=[last_conv_layer.output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def compute_saliency_map_fixed(model, img_array):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img_array)\n",
    "        predictions = model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "    grads = tape.gradient(loss, img_array)\n",
    "    saliency = tf.reduce_max(tf.abs(grads), axis=-1).numpy()\n",
    "    return saliency[0]\n",
    "\n",
    "test_image_array = x_c  # Replace 'processed_image' with your actual preprocessed variable\n",
    "\n",
    "if isinstance(test_image_array, list):\n",
    "    test_image_array = np.stack(test_image_array)  # Convert list of tensors to a single 4D tensor\n",
    "if len(test_image_array.shape) == 3:  # If missing batch dimension\n",
    "    test_image_array = np.expand_dims(test_image_array, axis=0)\n",
    "if len(test_image_array.shape) == 2:  # If missing channel dimension\n",
    "    test_image_array = np.expand_dims(test_image_array, axis=-1)\n",
    "\n",
    "test_image_array = tf.convert_to_tensor(test_image_array, dtype=tf.float32)\n",
    "\n",
    "last_conv_layer_name = None\n",
    "for layer in reversed(model.layers):\n",
    "    if 'conv' in layer.name:\n",
    "        last_conv_layer_name = layer.name\n",
    "        break\n",
    "\n",
    "if last_conv_layer_name is None:\n",
    "    raise ValueError(\"No convolutional layer found in the model.\")\n",
    "\n",
    "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "\n",
    "heatmap = get_gradcam_heatmap_fixed(model, test_image_array, last_conv_layer)\n",
    "plt.imshow(heatmap, cmap=\"jet\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "saliency = compute_saliency_map_fixed(model, test_image_array)\n",
    "plt.imshow(saliency, cmap=\"viridis\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Saliency Map\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "for i, j in enumerate(y_test):\n",
    "    k = predictions[i][0]\n",
    "    if j != k:\n",
    "        print(j, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_tests = 1\n",
    "# cnns = []\n",
    "# for i in range(num_tests):\n",
    "# cnns.append(cnn.CNN(x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnns[0].test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
