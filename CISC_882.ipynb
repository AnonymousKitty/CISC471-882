{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 05:09:47.553436: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-17 05:09:47.568997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734412187.587645     548 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734412187.593243     548 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 05:09:47.612645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import patient_data\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the folder path for the cancer and the non-cancer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = json.loads(open(\"./paths.json\").read())\n",
    "\n",
    "personal_path = all_paths['personal_path']\n",
    "cancerous_path = personal_path + all_paths['cancerous_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure GPUs is applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Num GPUs Available: ', len(physical_devices))\n",
    "if len(physical_devices) > 0:\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the DICOM files and preprocess/label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints was not processed correctly\n"
     ]
    }
   ],
   "source": [
    "# Using the patient_data data structure, load in all the patient data and save it in a dictionary with the folder name as the key\n",
    "def load_all_patients(path, add_label = False):\n",
    "    patients = np.array([])\n",
    "    folder = os.listdir(path)\n",
    "    # make shuffling and train/test split here\n",
    "    for name in folder:\n",
    "        patients= np.append(patients, patient_data.Patient(path, name, add_label))\n",
    "        if patients[-1].ct_paths == []:\n",
    "            print(name, \"was not processed correctly\")\n",
    "            patients = patients[:-1]\n",
    "    return patients\n",
    "\n",
    "patients = load_all_patients(cancerous_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients loaded: 422\n",
      "number of non-cancerous images in this dataset: 46726\n",
      "number of cancerous images in this dataset: 7610\n"
     ]
    }
   ],
   "source": [
    "num_nc = 0\n",
    "num_c = 0\n",
    "for i in patients:\n",
    "    num_nc += sum(1 for j in i.labels if j ==0)   \n",
    "    num_c += sum(1 for j in i.labels if j ==1)  \n",
    "\n",
    "print(\"number of patients loaded:\", len(patients))\n",
    "print(\"number of non-cancerous images in this dataset:\", num_nc)\n",
    "print(\"number of cancerous images in this dataset:\", num_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mix up the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m patients \u001b[38;5;241m=\u001b[39m shuffle(\u001b[43mpatients\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train-test split should be 80-20. \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Since the data has been shuffled, we can just grab the 1st 80% of the list and make it the train set and the remainder is the test set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_patients \u001b[38;5;241m=\u001b[39m patients[:math\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;28mlen\u001b[39m(patients) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patients' is not defined"
     ]
    }
   ],
   "source": [
    "# mix up the data\n",
    "patients = shuffle(patients)\n",
    "\n",
    "# Train-test split should be 80-20. \n",
    "# Since the data has been shuffled, we can just grab the 1st 80% of the list and make it the train set and the remainder is the test set\n",
    "train_patients = patients[:math.floor(len(patients) * 0.8)]\n",
    "test_patients = patients[math.floor(len(patients) * 0.8):]\n",
    "\n",
    "def save_imgs(dest, list_paths, list_labels):\n",
    "    cancerous_img_folder = dest + \"/cancerous\"\n",
    "    non_cancerous_img_folder = dest + \"/non_cancerous\"\n",
    "    if not os.path.exists(cancerous_img_folder):\n",
    "        os.makedirs(cancerous_img_folder)\n",
    "    if not os.path.exists(non_cancerous_img_folder):\n",
    "        os.makedirs(non_cancerous_img_folder)\n",
    "    # for our purposes, we know we dont want these folders to have any previous content, so remove anything in here if there is something\n",
    "    for file in glob.glob(cancerous_img_folder + \"/*\"):\n",
    "        os.remove(file)\n",
    "    for file in glob.glob(non_cancerous_img_folder + \"/*\"):\n",
    "        os.remove(file)\n",
    "    # save images\n",
    "    for i, dicom_path in enumerate(list_paths):\n",
    "        if list_labels[i] == 0:\n",
    "            img_folder = non_cancerous_img_folder\n",
    "        else:\n",
    "            img_folder = cancerous_img_folder\n",
    "        dicom = pydicom.dcmread(dicom_path)\n",
    "        pix_array = dicom.pixel_array\n",
    "        img = cv2.normalize(pix_array, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(f\"{img_folder}/image_{i}.jpg\", img)\n",
    "\n",
    "train_dest = personal_path + \"/train/train\"\n",
    "val_dest = personal_path + \"/train/validation\"\n",
    "test_dest = personal_path + \"/test\"\n",
    "\n",
    "\n",
    "# save_imgs(train_dest, train_patients)\n",
    "x_test, y_test = [], []\n",
    "for patient in test_patients:\n",
    "    x_test.extend(patient.ct_paths)\n",
    "    y_test.extend(patient.labels)\n",
    "save_imgs(test_dest, x_test, y_test)\n",
    "test_ds = ImageDataGenerator().flow_from_directory(\n",
    "        directory=test_dest, # the path to the test directory.\n",
    "        target_size=(512, 512),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "# split the train patients up into images and labels\n",
    "x_train, y_train = [], []\n",
    "for patient in train_patients:\n",
    "    x_train.extend(patient.ct_paths)\n",
    "    y_train.extend(patient.labels)\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "del train_patients\n",
    "del test_patients\n",
    "del patients\n",
    "# del x_test\n",
    "# del y_test\n",
    "# del x_train\n",
    "# del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom callback to clear any memory that is no longer being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training fold 1/5\n",
      "Found 35009 images belonging to 2 classes.\n",
      "Found 8753 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_1426']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 780ms/step - accuracy: 0.8847 - loss: 0.3257 - val_accuracy: 0.9159 - val_loss: 0.1874 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9807 - loss: 0.0574 - val_accuracy: 0.9669 - val_loss: 0.0847 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9959 - loss: 0.0176 - val_accuracy: 0.9709 - val_loss: 0.0732 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 740ms/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.9648 - val_loss: 0.0941 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.9729 - val_loss: 0.0762 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9717 - val_loss: 0.0794 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9781 - val_loss: 0.0642 - learning_rate: 5.0000e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9999 - loss: 7.9631e-04 - val_accuracy: 0.9788 - val_loss: 0.0611 - learning_rate: 5.0000e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 2.7157e-04 - val_accuracy: 0.9790 - val_loss: 0.0640 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 1.5125e-04 - val_accuracy: 0.9797 - val_loss: 0.0597 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 9.6378e-05 - val_accuracy: 0.9797 - val_loss: 0.0612 - learning_rate: 5.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 5.7045e-05 - val_accuracy: 0.9795 - val_loss: 0.0625 - learning_rate: 5.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 8.5943e-05 - val_accuracy: 0.9789 - val_loss: 0.0678 - learning_rate: 5.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 4.6410e-05 - val_accuracy: 0.9793 - val_loss: 0.0658 - learning_rate: 2.5000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 3.4476e-05 - val_accuracy: 0.9790 - val_loss: 0.0682 - learning_rate: 2.5000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_1426']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 158ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.39      0.47      1599\n",
      "           1       0.90      0.95      0.92      8975\n",
      "\n",
      "    accuracy                           0.87     10574\n",
      "   macro avg       0.74      0.67      0.70     10574\n",
      "weighted avg       0.85      0.87      0.85     10574\n",
      "\n",
      "\n",
      "Training fold 2/5\n",
      "Found 35009 images belonging to 2 classes.\n",
      "Found 8753 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 772ms/step - accuracy: 0.8884 - loss: 0.3098 - val_accuracy: 0.9199 - val_loss: 0.1848 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9784 - loss: 0.0601 - val_accuracy: 0.9702 - val_loss: 0.0744 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9950 - loss: 0.0184 - val_accuracy: 0.9746 - val_loss: 0.0648 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 0.9680 - val_loss: 0.0827 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 0.9690 - val_loss: 0.0899 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9774 - val_loss: 0.0613 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9761 - val_loss: 0.0698 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9703 - val_loss: 0.0906 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9567 - val_loss: 0.1753 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9985 - loss: 0.0078 - val_accuracy: 0.9775 - val_loss: 0.0687 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 3.4103e-04 - val_accuracy: 0.9681 - val_loss: 0.1065 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48      1599\n",
      "           1       0.90      0.94      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.73      0.68      0.70     10574\n",
      "weighted avg       0.85      0.86      0.85     10574\n",
      "\n",
      "\n",
      "Training fold 3/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 789ms/step - accuracy: 0.8757 - loss: 0.3438 - val_accuracy: 0.9186 - val_loss: 0.1833 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9756 - loss: 0.0692 - val_accuracy: 0.9592 - val_loss: 0.0972 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.9746 - val_loss: 0.0635 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.9601 - val_loss: 0.1124 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9782 - val_loss: 0.0568 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9790 - val_loss: 0.0584 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9498 - val_loss: 0.1471 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9966 - loss: 0.0122 - val_accuracy: 0.9745 - val_loss: 0.0820 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9798 - val_loss: 0.0608 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 746ms/step - accuracy: 1.0000 - loss: 3.4245e-04 - val_accuracy: 0.9807 - val_loss: 0.0605 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50      1599\n",
      "           1       0.91      0.94      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.69      0.71     10574\n",
      "weighted avg       0.85      0.86      0.86     10574\n",
      "\n",
      "\n",
      "Training fold 4/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 777ms/step - accuracy: 0.8922 - loss: 0.2614 - val_accuracy: 0.9230 - val_loss: 0.1782 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9805 - loss: 0.0522 - val_accuracy: 0.9749 - val_loss: 0.0622 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9953 - loss: 0.0166 - val_accuracy: 0.9762 - val_loss: 0.0597 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9975 - loss: 0.0098 - val_accuracy: 0.9774 - val_loss: 0.0623 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9808 - val_loss: 0.0560 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 742ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9737 - val_loss: 0.0828 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9647 - val_loss: 0.1030 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 741ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.9648 - val_loss: 0.1416 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9793 - val_loss: 0.0687 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9998 - loss: 9.8647e-04 - val_accuracy: 0.9817 - val_loss: 0.0710 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 153ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.41      1599\n",
      "           1       0.89      0.96      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.64      0.67     10574\n",
      "weighted avg       0.84      0.86      0.84     10574\n",
      "\n",
      "\n",
      "Training fold 5/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 779ms/step - accuracy: 0.8872 - loss: 0.3239 - val_accuracy: 0.9192 - val_loss: 0.2015 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9812 - loss: 0.0564 - val_accuracy: 0.9673 - val_loss: 0.0795 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9959 - loss: 0.0171 - val_accuracy: 0.9690 - val_loss: 0.0870 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9987 - loss: 0.0066 - val_accuracy: 0.9706 - val_loss: 0.0809 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 746ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9711 - val_loss: 0.0723 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9777 - val_loss: 0.0651 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9378 - val_loss: 0.1979 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9666 - val_loss: 0.0983 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9689 - val_loss: 0.0888 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9800 - val_loss: 0.0609 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 2.6140e-04 - val_accuracy: 0.9809 - val_loss: 0.0576 - learning_rate: 5.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 1.2230e-04 - val_accuracy: 0.9813 - val_loss: 0.0571 - learning_rate: 5.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 8.5970e-05 - val_accuracy: 0.9815 - val_loss: 0.0568 - learning_rate: 5.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 6.4669e-05 - val_accuracy: 0.9816 - val_loss: 0.0578 - learning_rate: 5.0000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 4.7905e-05 - val_accuracy: 0.9814 - val_loss: 0.0588 - learning_rate: 5.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 745ms/step - accuracy: 0.9999 - loss: 3.4057e-04 - val_accuracy: 0.9472 - val_loss: 0.1688 - learning_rate: 5.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9593 - val_loss: 0.1480 - learning_rate: 2.5000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 1.3452e-04 - val_accuracy: 0.9801 - val_loss: 0.0685 - learning_rate: 2.5000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 156ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47      1599\n",
      "           1       0.90      0.95      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.67      0.70     10574\n",
      "weighted avg       0.85      0.86      0.85     10574\n",
      "\n",
      "\n",
      "Average Accuracy Across 5 Folds: 0.8640\n"
     ]
    }
   ],
   "source": [
    "# Define K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train, y_train)):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    x_train_list, y_train_list = x_train[train_idx], y_train[train_idx]\n",
    "    x_val_list, y_val_list = x_train[val_idx], y_train[val_idx]\n",
    "\n",
    "    save_imgs(train_dest, x_train_list, y_train_list)\n",
    "    save_imgs(val_dest, x_val_list, y_val_list)   \n",
    "        \n",
    "    # Load the ResNet50 model pre-trained on ImageNet\n",
    "    model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(512, 512, 3)))\n",
    "    \n",
    "    # Custom layers\n",
    "    flattened = tf.keras.layers.Flatten()(model.output)\n",
    "    l2 = tf.keras.layers.Dense(128, activation='relu')(flattened)\n",
    "    l3 = tf.keras.layers.Dense(1, activation='sigmoid')(l2)\n",
    "    \n",
    "    # Define the full model\n",
    "    model = tf.keras.models.Model(inputs=model.input, outputs=l3)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00001),  # Use a smaller learning rate for end-to-end training\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    train_ds = ImageDataGenerator().flow_from_directory(\n",
    "            directory=train_dest, # the path to the training directory.\n",
    "            target_size=(512, 512),\n",
    "            batch_size=64,\n",
    "            class_mode=\"binary\",\n",
    "        )\n",
    "    val_ds = ImageDataGenerator().flow_from_directory(\n",
    "            directory=val_dest, # the path to the validation directory.\n",
    "            target_size=(512, 512),\n",
    "            batch_size=64,\n",
    "            class_mode=\"binary\",\n",
    "        )\n",
    "    \n",
    "\n",
    "    # Early stopping and learning rate scheduler\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "    \n",
    "    # Train the model directly using the training and validation data\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = (model.predict(test_ds) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(test_ds.classes, predictions, output_dict=True)\n",
    "    print(classification_report(test_ds.classes, predictions))\n",
    "    \n",
    "    # Save fold results\n",
    "    fold_results.append(report)\n",
    "    K.clear_session()\n",
    "\n",
    "# Aggregate results\n",
    "avg_accuracy = np.mean([fold['accuracy'] for fold in fold_results])\n",
    "print(f\"\\nAverage Accuracy Across {n_splits} Folds: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# x_data = np.array(x_c)/255  # Normalize the images\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# y_data = np.array(y_c)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Model training and evaluation loop\u001b[39;00m\n\u001b[1;32m      7\u001b[0m fold_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold\u001b[38;5;241m.\u001b[39msplit(\u001b[43mtrain_patients\u001b[49m, [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_patients))):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Split data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_patients' is not defined"
     ]
    }
   ],
   "source": [
    "# Define K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# x_data = np.array(x_c)/255  # Normalize the images\n",
    "# y_data = np.array(y_c)\n",
    "# Model training and evaluation loop\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_patients, [0]*len(train_patients))):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    p_train, p_val = train_patients[train_idx], train_patients[val_idx]\n",
    "    print('point a passed')\n",
    "\n",
    "#     # possible model to test\n",
    "#     model = Sequential([\n",
    "#         Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "#         Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "#         Conv2D(filters=64, kernel_size=(1, 1), activation='relu', padding='same'),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=1),\n",
    "#         Flatten(),\n",
    "#         Dense(units=1, activation='sigmoid')\n",
    "#     ])\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print('point b passed')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = np.array([])\n",
    "    for p in p_train:\n",
    "        x_train.extend(y for y in p.ct.data.values())\n",
    "        y_train = np.append(y_train, p.labels)\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_train = np.asarray(x_train)\n",
    "\n",
    "    x_val = []\n",
    "    y_val = np.array([])\n",
    "    for p in p_val:\n",
    "        x_val.extend(y for y in p.ct.data.values())\n",
    "        y_val = np.append(y_val, p.labels)\n",
    "    x_val, y_val = shuffle(x_val, y_val)\n",
    "    x_val = np.asarray(x_val)\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = datagen.flow(x_train, y_train, batch_size=16)\n",
    "    val_generator = datagen.flow(x_val, y_val, batch_size=16)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=32,\n",
    "        epochs=20,\n",
    "        callbacks=[MyCustomCallback()],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model architecture built\")\n",
    "    # Evaluate the model\n",
    "    predictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    # Save fold results\n",
    "    fold_results.append(report)\n",
    "    K.clear_session()\n",
    "\n",
    "# Aggregate results\n",
    "avg_accuracy = np.mean([fold['accuracy'] for fold in fold_results])\n",
    "print(f\"\\nAverage Accuracy Across {n_splits} Folds: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_test))\n",
    "for i, j in enumerate(y_test):\n",
    "    k = predictions[i][0]\n",
    "    if j != k:\n",
    "        print(j, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_tests = 1\n",
    "# cnns = []\n",
    "# for i in range(num_tests):\n",
    "# cnns.append(cnn.CNN(x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnns[0].test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
