{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 05:09:47.553436: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-17 05:09:47.568997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734412187.587645     548 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734412187.593243     548 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-17 05:09:47.612645: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gc\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import patient_data\n",
    "import pydicom\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the folder path for the cancer and the non-cancer images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = json.loads(open(\"./paths.json\").read())\n",
    "\n",
    "personal_path = all_paths['personal_path']\n",
    "cancerous_path = personal_path + all_paths['cancerous_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure GPUs is applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print('Num GPUs Available: ', len(physical_devices))\n",
    "if len(physical_devices) > 0:\n",
    "    for i in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(i, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the DICOM files and preprocess/label images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints was not processed correctly\n"
     ]
    }
   ],
   "source": [
    "# Using the patient_data data structure, load in all the patient data and save it in a dictionary with the folder name as the key\n",
    "def load_all_patients(path, add_label = False):\n",
    "    patients = np.array([])\n",
    "    folder = os.listdir(path)\n",
    "    # make shuffling and train/test split here\n",
    "    for name in folder:\n",
    "        patients= np.append(patients, patient_data.Patient(path, name, add_label))\n",
    "        if patients[-1].ct_paths == []:\n",
    "            print(name, \"was not processed correctly\")\n",
    "            patients = patients[:-1]\n",
    "    return patients\n",
    "\n",
    "patients = load_all_patients(cancerous_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients loaded: 422\n",
      "number of non-cancerous images in this dataset: 46726\n",
      "number of cancerous images in this dataset: 7610\n"
     ]
    }
   ],
   "source": [
    "num_nc = 0\n",
    "num_c = 0\n",
    "for i in patients:\n",
    "    num_nc += sum(1 for j in i.labels if j ==0)   \n",
    "    num_c += sum(1 for j in i.labels if j ==1)  \n",
    "\n",
    "print(\"number of patients loaded:\", len(patients))\n",
    "print(\"number of non-cancerous images in this dataset:\", num_nc)\n",
    "print(\"number of cancerous images in this dataset:\", num_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# mix up the data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m patients \u001b[38;5;241m=\u001b[39m shuffle(\u001b[43mpatients\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train-test split should be 80-20. \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Since the data has been shuffled, we can just grab the 1st 80% of the list and make it the train set and the remainder is the test set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_patients \u001b[38;5;241m=\u001b[39m patients[:math\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;28mlen\u001b[39m(patients) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.8\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patients' is not defined"
     ]
    }
   ],
   "source": [
    "# mix up the data\n",
    "patients = shuffle(patients)\n",
    "\n",
    "# Train-test split should be 80-20. \n",
    "# Since the data has been shuffled, we can just grab the 1st 80% of the list and make it the train set and the remainder is the test set\n",
    "train_patients = patients[:math.floor(len(patients) * 0.8)]\n",
    "test_patients = patients[math.floor(len(patients) * 0.8):]\n",
    "\n",
    "def save_imgs(dest, list_paths, list_labels):\n",
    "    cancerous_img_folder = dest + \"/cancerous\"\n",
    "    non_cancerous_img_folder = dest + \"/non_cancerous\"\n",
    "    if not os.path.exists(cancerous_img_folder):\n",
    "        os.makedirs(cancerous_img_folder)\n",
    "    if not os.path.exists(non_cancerous_img_folder):\n",
    "        os.makedirs(non_cancerous_img_folder)\n",
    "    # for our purposes, we know we dont want these folders to have any previous content, so remove anything in here if there is something\n",
    "    for file in glob.glob(cancerous_img_folder + \"/*\"):\n",
    "        os.remove(file)\n",
    "    for file in glob.glob(non_cancerous_img_folder + \"/*\"):\n",
    "        os.remove(file)\n",
    "    # save images\n",
    "    for i, dicom_path in enumerate(list_paths):\n",
    "        if list_labels[i] == 0:\n",
    "            img_folder = non_cancerous_img_folder\n",
    "        else:\n",
    "            img_folder = cancerous_img_folder\n",
    "        dicom = pydicom.dcmread(dicom_path)\n",
    "        pix_array = dicom.pixel_array\n",
    "        img = cv2.normalize(pix_array, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(f\"{img_folder}/image_{i}.jpg\", img)\n",
    "\n",
    "train_dest = personal_path + \"/train/train\"\n",
    "val_dest = personal_path + \"/train/validation\"\n",
    "test_dest = personal_path + \"/test\"\n",
    "\n",
    "\n",
    "# save_imgs(train_dest, train_patients)\n",
    "x_test, y_test = [], []\n",
    "for patient in test_patients:\n",
    "    x_test.extend(patient.ct_paths)\n",
    "    y_test.extend(patient.labels)\n",
    "save_imgs(test_dest, x_test, y_test)\n",
    "test_ds = ImageDataGenerator().flow_from_directory(\n",
    "        directory=test_dest, # the path to the test directory.\n",
    "        target_size=(512, 512),\n",
    "        batch_size=32,\n",
    "        class_mode=\"binary\",\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "# split the train patients up into images and labels\n",
    "x_train, y_train = [], []\n",
    "for patient in train_patients:\n",
    "    x_train.extend(patient.ct_paths)\n",
    "    y_train.extend(patient.labels)\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train)\n",
    "\n",
    "del train_patients\n",
    "del test_patients\n",
    "del patients\n",
    "# del x_test\n",
    "# del y_test\n",
    "# del x_train\n",
    "# del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom callback to clear any memory that is no longer being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect\n",
    "        tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training fold 1/5\n",
      "Found 35009 images belonging to 2 classes.\n",
      "Found 8753 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_1426']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 780ms/step - accuracy: 0.8847 - loss: 0.3257 - val_accuracy: 0.9159 - val_loss: 0.1874 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9807 - loss: 0.0574 - val_accuracy: 0.9669 - val_loss: 0.0847 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9959 - loss: 0.0176 - val_accuracy: 0.9709 - val_loss: 0.0732 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 740ms/step - accuracy: 0.9989 - loss: 0.0065 - val_accuracy: 0.9648 - val_loss: 0.0941 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.9729 - val_loss: 0.0762 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9717 - val_loss: 0.0794 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9781 - val_loss: 0.0642 - learning_rate: 5.0000e-06\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9999 - loss: 7.9631e-04 - val_accuracy: 0.9788 - val_loss: 0.0611 - learning_rate: 5.0000e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 2.7157e-04 - val_accuracy: 0.9790 - val_loss: 0.0640 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 1.5125e-04 - val_accuracy: 0.9797 - val_loss: 0.0597 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 9.6378e-05 - val_accuracy: 0.9797 - val_loss: 0.0612 - learning_rate: 5.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 5.7045e-05 - val_accuracy: 0.9795 - val_loss: 0.0625 - learning_rate: 5.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 8.5943e-05 - val_accuracy: 0.9789 - val_loss: 0.0678 - learning_rate: 5.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 4.6410e-05 - val_accuracy: 0.9793 - val_loss: 0.0658 - learning_rate: 2.5000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 1.0000 - loss: 3.4476e-05 - val_accuracy: 0.9790 - val_loss: 0.0682 - learning_rate: 2.5000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_1426']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 158ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.39      0.47      1599\n",
      "           1       0.90      0.95      0.92      8975\n",
      "\n",
      "    accuracy                           0.87     10574\n",
      "   macro avg       0.74      0.67      0.70     10574\n",
      "weighted avg       0.85      0.87      0.85     10574\n",
      "\n",
      "\n",
      "Training fold 2/5\n",
      "Found 35009 images belonging to 2 classes.\n",
      "Found 8753 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 772ms/step - accuracy: 0.8884 - loss: 0.3098 - val_accuracy: 0.9199 - val_loss: 0.1848 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9784 - loss: 0.0601 - val_accuracy: 0.9702 - val_loss: 0.0744 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9950 - loss: 0.0184 - val_accuracy: 0.9746 - val_loss: 0.0648 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9979 - loss: 0.0085 - val_accuracy: 0.9680 - val_loss: 0.0827 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 741ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 0.9690 - val_loss: 0.0899 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9774 - val_loss: 0.0613 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9761 - val_loss: 0.0698 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9703 - val_loss: 0.0906 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9567 - val_loss: 0.1753 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9985 - loss: 0.0078 - val_accuracy: 0.9775 - val_loss: 0.0687 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 1.0000 - loss: 3.4103e-04 - val_accuracy: 0.9681 - val_loss: 0.1065 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48      1599\n",
      "           1       0.90      0.94      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.73      0.68      0.70     10574\n",
      "weighted avg       0.85      0.86      0.85     10574\n",
      "\n",
      "\n",
      "Training fold 3/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 789ms/step - accuracy: 0.8757 - loss: 0.3438 - val_accuracy: 0.9186 - val_loss: 0.1833 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9756 - loss: 0.0692 - val_accuracy: 0.9592 - val_loss: 0.0972 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9951 - loss: 0.0195 - val_accuracy: 0.9746 - val_loss: 0.0635 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.9601 - val_loss: 0.1124 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9782 - val_loss: 0.0568 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9790 - val_loss: 0.0584 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9498 - val_loss: 0.1471 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9966 - loss: 0.0122 - val_accuracy: 0.9745 - val_loss: 0.0820 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9798 - val_loss: 0.0608 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 746ms/step - accuracy: 1.0000 - loss: 3.4245e-04 - val_accuracy: 0.9807 - val_loss: 0.0605 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 155ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.45      0.50      1599\n",
      "           1       0.91      0.94      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.69      0.71     10574\n",
      "weighted avg       0.85      0.86      0.86     10574\n",
      "\n",
      "\n",
      "Training fold 4/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 777ms/step - accuracy: 0.8922 - loss: 0.2614 - val_accuracy: 0.9230 - val_loss: 0.1782 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9805 - loss: 0.0522 - val_accuracy: 0.9749 - val_loss: 0.0622 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9953 - loss: 0.0166 - val_accuracy: 0.9762 - val_loss: 0.0597 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9975 - loss: 0.0098 - val_accuracy: 0.9774 - val_loss: 0.0623 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9808 - val_loss: 0.0560 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 742ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9737 - val_loss: 0.0828 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9647 - val_loss: 0.1030 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 741ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.9648 - val_loss: 0.1416 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9793 - val_loss: 0.0687 - learning_rate: 5.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9998 - loss: 9.8647e-04 - val_accuracy: 0.9817 - val_loss: 0.0710 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 153ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.41      1599\n",
      "           1       0.89      0.96      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.64      0.67     10574\n",
      "weighted avg       0.84      0.86      0.84     10574\n",
      "\n",
      "\n",
      "Training fold 5/5\n",
      "Found 35010 images belonging to 2 classes.\n",
      "Found 8752 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 779ms/step - accuracy: 0.8872 - loss: 0.3239 - val_accuracy: 0.9192 - val_loss: 0.2015 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9812 - loss: 0.0564 - val_accuracy: 0.9673 - val_loss: 0.0795 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9959 - loss: 0.0171 - val_accuracy: 0.9690 - val_loss: 0.0870 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 0.9987 - loss: 0.0066 - val_accuracy: 0.9706 - val_loss: 0.0809 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 746ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9711 - val_loss: 0.0723 - learning_rate: 1.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 0.9777 - val_loss: 0.0651 - learning_rate: 1.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9378 - val_loss: 0.1979 - learning_rate: 1.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 0.9969 - loss: 0.0102 - val_accuracy: 0.9666 - val_loss: 0.0983 - learning_rate: 1.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 742ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9689 - val_loss: 0.0888 - learning_rate: 1.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9800 - val_loss: 0.0609 - learning_rate: 5.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 2.6140e-04 - val_accuracy: 0.9809 - val_loss: 0.0576 - learning_rate: 5.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 1.2230e-04 - val_accuracy: 0.9813 - val_loss: 0.0571 - learning_rate: 5.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 8.5970e-05 - val_accuracy: 0.9815 - val_loss: 0.0568 - learning_rate: 5.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 6.4669e-05 - val_accuracy: 0.9816 - val_loss: 0.0578 - learning_rate: 5.0000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 4.7905e-05 - val_accuracy: 0.9814 - val_loss: 0.0588 - learning_rate: 5.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 745ms/step - accuracy: 0.9999 - loss: 3.4057e-04 - val_accuracy: 0.9472 - val_loss: 0.1688 - learning_rate: 5.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 744ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9593 - val_loss: 0.1480 - learning_rate: 2.5000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 743ms/step - accuracy: 1.0000 - loss: 1.3452e-04 - val_accuracy: 0.9801 - val_loss: 0.0685 - learning_rate: 2.5000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda-envs/venv2/lib/python3.12/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(32, 512, 512, 3))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 156ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47      1599\n",
      "           1       0.90      0.95      0.92      8975\n",
      "\n",
      "    accuracy                           0.86     10574\n",
      "   macro avg       0.74      0.67      0.70     10574\n",
      "weighted avg       0.85      0.86      0.85     10574\n",
      "\n",
      "\n",
      "Average Accuracy Across 5 Folds: 0.8640\n"
     ]
    }
   ],
   "source": [
    "# Define K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(x_train, y_train)):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    x_train_list, y_train_list = x_train[train_idx], y_train[train_idx]\n",
    "    x_val_list, y_val_list = x_train[val_idx], y_train[val_idx]\n",
    "\n",
    "    save_imgs(train_dest, x_train_list, y_train_list)\n",
    "    save_imgs(val_dest, x_val_list, y_val_list)   \n",
    "        \n",
    "    # Load the ResNet50 model pre-trained on ImageNet\n",
    "    model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(512, 512, 3)))\n",
    "    \n",
    "    # Custom layers\n",
    "    flattened = tf.keras.layers.Flatten()(model.output)\n",
    "    l2 = tf.keras.layers.Dense(128, activation='relu')(flattened)\n",
    "    l3 = tf.keras.layers.Dense(1, activation='sigmoid')(l2)\n",
    "    \n",
    "    # Define the full model\n",
    "    model = tf.keras.models.Model(inputs=model.input, outputs=l3)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00001),  # Use a smaller learning rate for end-to-end training\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    train_ds = ImageDataGenerator().flow_from_directory(\n",
    "            directory=train_dest, # the path to the training directory.\n",
    "            target_size=(512, 512),\n",
    "            batch_size=64,\n",
    "            class_mode=\"binary\",\n",
    "        )\n",
    "    val_ds = ImageDataGenerator().flow_from_directory(\n",
    "            directory=val_dest, # the path to the validation directory.\n",
    "            target_size=(512, 512),\n",
    "            batch_size=64,\n",
    "            class_mode=\"binary\",\n",
    "        )\n",
    "    \n",
    "\n",
    "    # Early stopping and learning rate scheduler\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "    \n",
    "    # Train the model directly using the training and validation data\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = (model.predict(test_ds) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(test_ds.classes, predictions, output_dict=True)\n",
    "    print(classification_report(test_ds.classes, predictions))\n",
    "    \n",
    "    # Save fold results\n",
    "    fold_results.append(report)\n",
    "    K.clear_session()\n",
    "\n",
    "# Aggregate results\n",
    "avg_accuracy = np.mean([fold['accuracy'] for fold in fold_results])\n",
    "print(f\"\\nAverage Accuracy Across {n_splits} Folds: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_patients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# x_data = np.array(x_c)/255  # Normalize the images\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# y_data = np.array(y_c)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Model training and evaluation loop\u001b[39;00m\n\u001b[1;32m      7\u001b[0m fold_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold\u001b[38;5;241m.\u001b[39msplit(\u001b[43mtrain_patients\u001b[49m, [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_patients))):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Split data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_patients' is not defined"
     ]
    }
   ],
   "source": [
    "# Define K-Fold Cross-Validation\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "# x_data = np.array(x_c)/255  # Normalize the images\n",
    "# y_data = np.array(y_c)\n",
    "# Model training and evaluation loop\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_patients, [0]*len(train_patients))):\n",
    "    print(f\"\\nTraining fold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Split data\n",
    "    p_train, p_val = train_patients[train_idx], train_patients[val_idx]\n",
    "    print('point a passed')\n",
    "\n",
    "#     # possible model to test\n",
    "#     model = Sequential([\n",
    "#         Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "#         Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "#         Conv2D(filters=64, kernel_size=(1, 1), activation='relu', padding='same'),\n",
    "#         MaxPool2D(pool_size=(2, 2), strides=1),\n",
    "#         Flatten(),\n",
    "#         Dense(units=1, activation='sigmoid')\n",
    "#     ])\n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(512, 512, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print('point b passed')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = np.array([])\n",
    "    for p in p_train:\n",
    "        x_train.extend(y for y in p.ct.data.values())\n",
    "        y_train = np.append(y_train, p.labels)\n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_train = np.asarray(x_train)\n",
    "\n",
    "    x_val = []\n",
    "    y_val = np.array([])\n",
    "    for p in p_val:\n",
    "        x_val.extend(y for y in p.ct.data.values())\n",
    "        y_val = np.append(y_val, p.labels)\n",
    "    x_val, y_val = shuffle(x_val, y_val)\n",
    "    x_val = np.asarray(x_val)\n",
    "    \n",
    "    datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = datagen.flow(x_train, y_train, batch_size=16)\n",
    "    val_generator = datagen.flow(x_val, y_val, batch_size=16)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=32,\n",
    "        epochs=20,\n",
    "        callbacks=[MyCustomCallback()],\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Model architecture built\")\n",
    "    # Evaluate the model\n",
    "    predictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    # Save fold results\n",
    "    fold_results.append(report)\n",
    "    K.clear_session()\n",
    "\n",
    "# Aggregate results\n",
    "avg_accuracy = np.mean([fold['accuracy'] for fold in fold_results])\n",
    "print(f\"\\nAverage Accuracy Across {n_splits} Folds: {avg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix to visualize results of the last fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 633  966]\n",
      " [ 463 8512]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "cm = confusion_matrix(y_true=test_ds.classes, y_pred=predictions)\n",
    "cm_plot_labels = ['cancer','no_cancer']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_tests = 1\n",
    "# cnns = []\n",
    "# for i in range(num_tests):\n",
    "# cnns.append(cnn.CNN(x_train, x_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation and bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnns[0].test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
